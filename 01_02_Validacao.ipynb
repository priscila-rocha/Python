{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c7b58b500e937f7d0f80b1920b86b86d054634e7"
   },
   "source": [
    "## Scikit-Learn é uma biblioteca que auxilia na validação do modelo.\n",
    "\n",
    "A separação de dados em treino e teste é muito importante para ter-se condições de avaliar o desempenho de um modelo em dados que ainda não foram vistos. Na verdade, dados ainda não vistos são o foco de aprendizado de máquina, visto que ao desenvolver-se sistemas, o principal objetivo é colocá-los em produção e ter performance aceitável (confiável).\n",
    "\n",
    "Existe uma subdivisão dos dados de treino que pode ser o conjunto de validação. O conjunto de validação pode, por exemplo, participar de um processo de melhoria do modelo. Uma vez que o modelo está aperfeiçoado suficiente, então ele é avaliado no conjunto de teste."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "source": [
    "Vamos explorar um conjunto de dados diferentes: uma base de vinhos; separar os dados e verificar como a mudança de parâmetros afeta o resultado. Há uma forma automatizada de fazer isso, mas isso será conteúdo do próximo encontro. Por enquanto, vamos fazer tudo manualmente para entender o processo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_wine\n",
    "wine = load_wine()\n",
    "\n",
    "data = wine.data\n",
    "target = wine.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "90beb882502d5f323484877012f765f1c0b230c5"
   },
   "outputs": [],
   "source": [
    "# separando os dados em treino e teste\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.33, random_state=42)\n",
    "\n",
    "# separando o conjunto de treino em validação também\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "b30dbc5b4a5cc978cca307647fe6d0ebcd0939b9"
   },
   "source": [
    "Agora, os dados estão divididos em três blocos disjuntos: treino, validação e teste. \n",
    "* O teste representa aproximadamente 33% da quantidade dados;\n",
    "* A validação representa aproximadamente 22% (66% x 33%) do total de dados; e\n",
    "* O treino representa aproximadamente 44% da quantidade de dados originais;\n",
    "\n",
    "A seguir, será comparado o desempenho do KNN treinado com o conjunto de treino e testado no conjunto de validação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "215594583e93cda8d295411b27b1a49f4331da2c"
   },
   "outputs": [],
   "source": [
    "# treinando o modelo \n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# avaliando o modelo\n",
    "from sklearn.metrics import accuracy_score\n",
    "y_pred = knn.predict(X_val)\n",
    "accuracy_score(y_val, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "35ee76e398263541cf9ffa307070da4903a10844"
   },
   "source": [
    "O resultado mostra a princípio como a redução na quantidade de dados de treino impacta o desempenho do método. Esse conjunto de validação é bastante importante para servir como um tipo de teste e analisar a relação de melhoria ou piora com a mudança de parâmetros no método de aprendizagem.\n",
    "\n",
    "Vamos supor testes com diferentes valores de *k* (n_neighbors) no método k-NN. Vamos mostrar o desempenho a cada mudança de parâmetro, e também vamos salvar o modelo sempre que um resultado maior for obtido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "a0d03491ed77beecc60bb141d58a5b787148896d"
   },
   "outputs": [],
   "source": [
    "best_model = None\n",
    "best_accuracy = 0\n",
    "\n",
    "for k in [1,2,3,4,5]:\n",
    "\n",
    "    knn = KNeighborsClassifier(n_neighbors = k) # a cada passo, o parâmetro assume um valor\n",
    "    knn.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = knn.predict(X_val)\n",
    "    acc = accuracy_score(y_val, y_pred)\n",
    "    print('K:', k, '- ACC:', acc)\n",
    "    \n",
    "    if acc > best_accuracy:\n",
    "        best_model = knn\n",
    "        best_accuracy = acc\n",
    "        \n",
    "y_pred = best_model.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print()\n",
    "print('Melhor modelo:')\n",
    "print('K:', best_model.get_params()['n_neighbors'], '- ACC:', acc * 100) #corrigir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "6e951f78fd26740efce34ba404a52cebe720546b"
   },
   "source": [
    "No trecho de código anterior, foi avaliado o desempenho do método de aprendizagem usando 5 parametrizações diferentes: k = 1, 2, 3, 4 e 5. Em vez de fazer essa verificação diretamente no conjunto de teste, essa verificação deve ser feita no conjunto de validação quando houver dados suficiente. No exemplo anterior, o melhor resultado foi obtido com k = 1. Assim, o modelo salvo como *melhor modelo* foi k = 1, e foi esse modelo o escolhido para ser utilizado na verificação de performance com o conjunto de teste."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "3e4ce0c19ae1701bc1436a20127193ccff9a451d"
   },
   "source": [
    "Agora que o conjunto de teste está totalmente isolado e não é usado para definir melhores parâmetros, é importante se atentar para outra questão: suponha que, por acaso, as amostras mais fáceis tenham caído no conjunto de teste. Isso vai influenciar o resultado positivamente, gerando uma falsa impressão de que o método de aprendizagem trouxe bons resultados. Aqui duas saídas são possíveis: embaralhar os dados e rodar o mesmo experimento várias vezes ou utilizar validação cruzada.\n",
    "\n",
    "**Os experimentos feitos até aqui usaram a estratégia de validação hold-out**, onde uma parcela dos dados é isolada e utilizada para verificar o desempenho do modelo. Na primeira proposta para contornar o problema de amostras muito fáceis caírem no conjunto de teste, sugeriu-se usar várias vezes o hold-out com embaralhamento das amostras. Embora aplicável, estatisticamente existe um grau de cetismo da viabilidade disso. Isso porque não há garantias de que todas as amostras em algum momento estarão no conjunto de teste. *A solução de garantia é a validação cruzada ou cross-validation.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "5a2845271357a72b629d89fc13270f34267a64c5"
   },
   "outputs": [],
   "source": [
    "# embaralhando os dados várias vezes e re-executando o experimento\n",
    "import numpy as np\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "ss = ShuffleSplit(n_splits=5, test_size=0.2, random_state=0) # 5 execuções diferentes com 20% dos dados para teste\n",
    "\n",
    "acc = []\n",
    "for train_index, test_index in ss.split(data):\n",
    "    knn = KNeighborsClassifier(n_neighbors = 1)\n",
    "    knn.fit(data[train_index],target[train_index])\n",
    "    y_pred = knn.predict(data[test_index])\n",
    "    acc.append(accuracy_score(y_pred,target[test_index]))\n",
    "\n",
    "acc = np.asarray(acc) # converte pra numpy pra ficar mais simples de usar média e desvio padrão\n",
    "print(acc)\n",
    "print('Acurácia - %.2f +- %.2f' % (acc.mean() * 100, acc.std() * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "144145e065be7e3fc2492158391617fc4719a2b7"
   },
   "source": [
    "Aqui é importante perceber a diferença da acurácia entre essa validação (repetindo 5 vezes o experimento) e o bloco de código anterior. Na situação anterior, o modelo de k-NN com k = 1 chegou próximo a 78% de acurácia, enquanto que ao repetir o experimento, a média foi 71,11% com desvio de 8.89%, que é bastante coisa. **Pode-se dizer que é mais confiável afirmar que esse modelo tem acurácia em torno de 71% do que 78%.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "59f951d3d25755b1ccde7f06271a69280775ce83"
   },
   "source": [
    "A validação cruzada pode ser feita de várias formas no Scikit-Learn, mas é importante observar que agora não temos mais apenas um resultado para o desempenho do modelo. Teremos um resultado para cada execução, então é necessário olhar para essas informações pela perspectiva da média e desvio padrão. As funções do Scikit-Learn que auxiliarão na validação cruzada são: *KFold* e *cross_val_score*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "96a2df397e8bde8543f3bb4318b6811ba0a89a11"
   },
   "outputs": [],
   "source": [
    "# utilizando validação cruzada com cross_val_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "knn = KNeighborsClassifier(n_neighbors = 1)\n",
    "scores = cross_val_score(knn, data, target, cv=5) # 5 execuções diferentes com 20% dos dados para teste\n",
    "\n",
    "print('Acurácia - %.2f +- %.2f' % (scores.mean() * 100, scores.std() * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d79b7fb7b5eef80469665473ff3fc0cf6312bfce"
   },
   "outputs": [],
   "source": [
    "# utilizando validação cruzada com KFold\n",
    "from sklearn.model_selection import KFold\n",
    "kf = KFold(n_splits = 5)\n",
    "\n",
    "acc = []\n",
    "for train_index, test_index in kf.split(data):\n",
    "    knn = KNeighborsClassifier(n_neighbors = 1)\n",
    "    knn.fit(data[train_index],target[train_index])\n",
    "    y_pred = knn.predict(data[test_index])\n",
    "    acc.append(accuracy_score(y_pred,target[test_index]))\n",
    "\n",
    "acc = np.asarray(acc) # converte pra numpy pra ficar mais simples de usar média e desvio padrão\n",
    "print(acc)\n",
    "print('Acurácia - %.2f +- %.2f' % (acc.mean() * 100, acc.std() * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "6c34fd0003e43ffd3dbc3dee27fa872e78cbc30f"
   },
   "source": [
    "Os dois blocos de cima demonstram duas maneiras de aplicar a validação cruzada a um modelo. Enquanto o primeiro afirma que a acurácia do modelo é em torno de 72%, o segundo alega 63% com desvio de 23% (que é muito alto). O primeiro tem o objetivo de avaliar o desempenho baseado em uma métrica, enquanto o segundo oferece quais os índices (linhas) que participarão de cada rodada ou execução, dando maior flexibilidade para o programador.\n",
    "\n",
    "**Mas por que uma diferença tão grande?** A resposta é um conceito do campo de estatística: estratificação. Ter um conjunto estratificado significa que ele é representativo. Ou seja, se sua amostra tem 30 amostras da classe positiva e 30 da classe negativa, ao separar em um conjunto menor, é esperado que mantenha-se essa proporção (50/50). Enquanto que o cross_val_score faz a divisão considerando a estratificação, o KFold não o faz. Para isso, existe uma variante dessa função chamada StratifiedKFold. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "83b26d7af62d5a09609f91d6858e7288713af332"
   },
   "outputs": [],
   "source": [
    "# utilizando validação cruzada com KFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "kf = StratifiedKFold(n_splits = 5)\n",
    "\n",
    "acc = []\n",
    "for train_index, test_index in kf.split(data, target): # precisa passar as classes agora para que a divisão aconteça\n",
    "    knn = KNeighborsClassifier(n_neighbors = 1)\n",
    "    knn.fit(data[train_index],target[train_index])\n",
    "    y_pred = knn.predict(data[test_index])\n",
    "    acc.append(accuracy_score(y_pred,target[test_index]))\n",
    "\n",
    "acc = np.asarray(acc) # converte pra numpy pra ficar mais simples de usar média e desvio padrão\n",
    "print('Acurácia - %.2f +- %.2f' % (acc.mean() * 100, acc.std() * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "be4a3eadb25fe7153a69ae222f5c391e0ffe9c53"
   },
   "source": [
    "Para esse método de aprendizagem, o conjunto de dados wine parece ser mais difícil de classificar. Diferente da Iris, que ficava em torno de 98%, esse conjunto dificilmente passou dos 80%.\n",
    "Vamos aplicar a visualização desses dados para verificar se eles são muito aglomerados ou linearmente separáveis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "9259debcdab71e96ad682b664727fa91563b156d"
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "X_r = pca.fit_transform(data)\n",
    "\n",
    "colors = ['navy', 'turquoise', 'darkorange']\n",
    "for color, i, target_name in zip(colors, [0, 1, 2], wine.target_names):\n",
    "    plt.scatter(X_r[target == i, 0], X_r[target == i, 1], color=color, alpha=.8, label=target_name)\n",
    "plt.legend(loc='best', shadow=False, scatterpoints=1)\n",
    "plt.title('PCA')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "96d9cfa303d167a5616a8a605b1d2bfdb0290efa"
   },
   "source": [
    "Os dados estão bastante aglomerados em algumas regiões, dificultando o funcionamento de métodos de aprendizagem baseados em distância e funções lineares. Os dados naturalmente têm essa característica, mas é sempre importante verificar se essa aglomeração de informação não é devido a escala dos atributos. Isso, inclusive, é extremamente prejudicial para métodos baseados em distância."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "38d4a8a51959d2071deeb0da6b1d8dbc6b86aba0"
   },
   "outputs": [],
   "source": [
    "# verificando a escala dos atributos\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(data)\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "2ef7de6304e95ffcc25fe95210c30c198c65adfa"
   },
   "source": [
    "A biblioteca Pandas tem uma forma fácil de visualizar algumas informações estatísticas sobre um conjunto de dados. No bloco acima, é possível perceber que alguns atributos estão em escalas completamente diferente de outros. Por exemplo, compare o atributo 0 e o atributo 12, ou 0 e 7. Escalas diferentes confundem os métodos baseados em distância. Sabendo disso, uma estratégia é colocar os dados para respeitar um padrão ou distribuição. Isso pode ser feito com o StandardScaler do Scikit-Learn. Vamos verificar como fica a distribuição dos dados após padronizá-los e a visualização em 2D."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "4930607a0f558b07c5e889effb6e8cbe9bce580b"
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(data)\n",
    "data_s = scaler.transform(data)\n",
    "\n",
    "df = pd.DataFrame(data_s)\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "6970b71d2c70dcd33fbb9bbec5261685cd0436dc"
   },
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "X_r = pca.fit_transform(data_s)\n",
    "\n",
    "colors = ['navy', 'turquoise', 'darkorange']\n",
    "for color, i, target_name in zip(colors, [0, 1, 2], wine.target_names):\n",
    "    plt.scatter(X_r[target == i, 0], X_r[target == i, 1], color=color, alpha=.8, label=target_name)\n",
    "plt.legend(loc='best', shadow=False, scatterpoints=1)\n",
    "plt.title('PCA')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "91bea5e4a7edb7c32d271ab989d4f2f16f08091e"
   },
   "source": [
    "Os dados agora estão todos muito próximos de 0 com desvio padrão 1, e isso melhora a disposição gráfica como pode ser visto na imagem. Não há mais tanto aglomeração, e existe separações lineares mais visíveis. Isso são fortes indícios de que agora um método de aprendizagem terá melhor desempenho. No entanto, enquanto para visualizar o StandardScaler foi aplicado em toda a base, é importante perceber que ao testar o modelo, **o StandardScaler só pode ter dados de treino no fit**. Ou seja, ele não pode conhecer a disposição dos dados de teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "5ed4e2725a261d686e726dc6aa8487fffa0e071f"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "kf = StratifiedKFold(n_splits = 5)\n",
    "\n",
    "acc = []\n",
    "for train_index, test_index in kf.split(data, target): # precisa passar as classes agora para que a divisão aconteça\n",
    "    knn = KNeighborsClassifier(n_neighbors = 1)\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    train = scaler.fit_transform(data[train_index]) # somente dados de treino no fit\n",
    "    test = scaler.transform(data[test_index]) # aplica-se transform no teste apenas\n",
    "    \n",
    "    knn.fit(train,target[train_index])\n",
    "    y_pred = knn.predict(test)\n",
    "    acc.append(accuracy_score(y_pred,target[test_index]))\n",
    "\n",
    "acc = np.asarray(acc) # converte pra numpy pra ficar mais simples de usar média e desvio padrão\n",
    "print('Acurácia - %.2f +- %.2f' % (acc.mean() * 100, acc.std() * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "5c99d1e366dae3e1ddfa25c2bfcf8da4304651de"
   },
   "source": [
    "Os resultados melhoraram substancionalmente e são confiáveis, visto que foram avaliados numa estratégia de validação cruzada com 5 partições."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "45b343296fe52514fe43195f8b64033c71b46d3c"
   },
   "source": [
    "Um último passo é integrar na validação cruzada a pesquisa pelos melhores parâmetros, algo semelhante ao que foi feito anteriormente. Novamente, o Scikit-Learn tem uma função para facilitar o processo chamada *GridSearchCV*. A dificuldade nesse ponto aparece ao perceber como será formado o fluxo, afinal não pode-se procurar os melhores parâmetros a cada execução da validação cruzada, uma vez que a validação cruzada tem o objetivo de avaliar um modelo e a mudança de parâmetro a cada execução criaria um modelo novo. Isso criaria um loop infinito de tentativas de avaliar um modelo.\n",
    "\n",
    "A solução é separar um conjunto de dados para fazer a busca pelos melhores parâmetros e formar um modelo. Assumindo que esse conjunto utilizado para esse propósito é representativo, avalia-se então com a validação cruzada qual o desempenho desse modelo. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utilizando validação cruzada com cross_val_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "pipeline = Pipeline([('scaler', StandardScaler()), ('clf', KNeighborsClassifier(n_neighbors = 1))])\n",
    "scores = cross_val_score(pipeline, data, target, cv=5) # 5 execuções diferentes com 20% dos dados para teste\n",
    "\n",
    "print('Acurácia - %.2f +- %.2f' % (scores.mean() * 100, scores.std() * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "5ea3cea33dc00d1116d27d2c3f2deac97794704e"
   },
   "outputs": [],
   "source": [
    "# separa-se uma parcela para encontrar os melhores parâmetros (5% do original)\n",
    "data_gs, data_cv, target_gs, target_cv = train_test_split(data, target, test_size=0.95, random_state=42, stratify=target)\n",
    "\n",
    "# uma forma automática de StandardScaler + CLF\n",
    "from sklearn.pipeline import Pipeline\n",
    "pipeline = Pipeline([('scaler', StandardScaler()), ('clf', KNeighborsClassifier())])\n",
    "\n",
    "# utiliza-se GridSearchCV para achar os melhores parâmetros\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "parameters = {'clf__n_neighbors': [1,2,3,4,5], 'clf__weights' : ['uniform','distance']} # quais parâmetros e quais valores serão testados\n",
    "clf = GridSearchCV(pipeline, parameters, cv=3, iid=False) # clf vai armazenar qual foi a melhor configuração\n",
    "clf.fit(data_gs, target_gs)\n",
    "\n",
    "print(clf.best_params_)\n",
    "\n",
    "# utilizando validação cruzada para avaliar o modelo\n",
    "scores = cross_val_score(clf.best_estimator_, data_cv, target_cv, cv=5)\n",
    "print('Acurácia - %.2f +- %.2f' % (scores.mean() * 100, scores.std() * 100))\n",
    "\n",
    "clf = clf.best_estimator_\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "kf = StratifiedKFold(n_splits = 5)\n",
    "\n",
    "acc = []\n",
    "for train_index, test_index in kf.split(data_cv, target_cv): # precisa passar as classes agora para que a divisão aconteça\n",
    "    \n",
    "    #scaler = StandardScaler()\n",
    "    #train = scaler.fit_transform(data_cv[train_index]) # somente dados de treino no fit\n",
    "    #test = scaler.transform(data_cv[test_index]) # aplica-se transform no teste apenas\n",
    "    \n",
    "    clf.fit(data_cv[train_index],target_cv[train_index])\n",
    "    y_pred = clf.predict(data_cv[test_index])\n",
    "    acc.append(accuracy_score(y_pred,target_cv[test_index]))\n",
    "\n",
    "acc = np.array(acc)\n",
    "print('Acurácia - %.2f +- %.2f' % (acc.mean() * 100, acc.std() * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "797c509f9309074bf8d9b7995b7718a74a905ba9"
   },
   "source": [
    "O resultado melhorou ainda mais ao pesquisar qual era a melhor configuração de atributos, antes de avaliar a performance do modelo no conjunto de teste. O conceito e a função de Pipeline serão abordados com mais detalhes nos próximos encontros, então não se desespere.\n",
    "\n",
    "Conclui-se aqui essa breve discussão e apresentação sobre divisão de dados, onde você pode ter aprendido sobre:\n",
    "* separação dos dados em treino, validação e teste;\n",
    "* normalização dos dados;\n",
    "* validação cruzada; e\n",
    "* busca pelos melhores parâmetros."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "e8240c0485b01f706d7d2f2476c2056614c0cf0f"
   },
   "source": [
    "# Exercício\n",
    "\n",
    "* Com o conjunto de dados sobre *câncer de mama*, **tente obter o melhor desempenho de acurácia**. \n",
    "\n",
    "* Organize e **tenha cuidado** para que seu experimento execute um *protocolo de validação que faça sentido*.\n",
    "\n",
    "Mais informações sobre esse conjunto de dados poderão ser obtidas em: \n",
    "[https://scikit-learn.org/stable/datasets/index.html#breast-cancer-dataset](https://scikit-learn.org/stable/datasets/index.html#breast-cancer-dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "6b5ab284eb392e24866598e96db40bb140310f27"
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "breast_cancer = load_breast_cancer()\n",
    "X = breast_cancer.data\n",
    "y = breast_cancer.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
